"""
Probe Query Tool - åŸºäºŽ AgenticX çš„ BaseTool

è¿™æ˜¯ Agent-First çš„æ ¸å¿ƒå·¥å…·ï¼Œå°†è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬æ¢ä¸ºæ™ºèƒ½åŒ–çš„æ•°æ®åº“æŸ¥è¯¢
"""

import time
from typing import Any, Dict, Optional
from agenticx import BaseTool
from .models import ProbeRequest, ProbeResponse, QueryStage, PrecisionLevel


class ProbeQueryTool(BaseTool):
    """
    Probe æŸ¥è¯¢å·¥å…·
    
    åŸºäºŽ AgenticX çš„ BaseToolï¼Œæ”¯æŒï¼š
    - è‡ªç„¶è¯­è¨€æŸ¥è¯¢
    - æŸ¥è¯¢é˜¶æ®µæ„ŸçŸ¥
    - åŠ¨æ€ç²¾åº¦æŽ§åˆ¶
    - è¯­ä¹‰ç¼“å­˜
    """
    
    name: str = "probe_query"
    description: str = """
    æ‰§è¡Œæ™ºèƒ½åŒ–çš„æ•°æ®åº“æŸ¥è¯¢ï¼Œç†è§£æŸ¥è¯¢æ„å›¾å’Œé˜¶æ®µã€‚
    
    å‚æ•°ï¼š
    - natural_query: è‡ªç„¶è¯­è¨€æŸ¥è¯¢æè¿°
    - stage: æŸ¥è¯¢é˜¶æ®µ (metadata_exploration/solution_formulation/full_validation)
    - precision: ç²¾åº¦è¦æ±‚ (approximate/sample/exact)
    - context: æŸ¥è¯¢ä¸Šä¸‹æ–‡
    """
    
    def __init__(
        self,
        database_connector=None,
        memory_store=None,
        llm_provider=None
    ):
        """
        åˆå§‹åŒ– Probe Tool
        
        Args:
            database_connector: æ•°æ®åº“è¿žæŽ¥å™¨
            memory_store: AgenticMemoryStoreï¼ˆç”¨äºŽç¼“å­˜ï¼‰
            llm_provider: LLMï¼ˆç”¨äºŽè§£æžè‡ªç„¶è¯­è¨€ï¼‰
        """
        super().__init__()
        self.database = database_connector
        self.memory_store = memory_store
        self.llm_provider = llm_provider
        self.query_count = 0
        self.cache_hits = 0
    
    async def aexecute(
        self,
        natural_query: str,
        stage: str = "full_validation",
        precision: str = "exact",
        context: str = "",
        **kwargs
    ) -> Dict[str, Any]:
        """
        å¼‚æ­¥æ‰§è¡Œ Probe æŸ¥è¯¢ï¼ˆAgenticX BaseTool è¦æ±‚çš„æ–¹æ³•ï¼‰
        
        Args:
            natural_query: è‡ªç„¶è¯­è¨€æŸ¥è¯¢
            stage: æŸ¥è¯¢é˜¶æ®µ
            precision: ç²¾åº¦çº§åˆ«
            context: æŸ¥è¯¢ä¸Šä¸‹æ–‡
            
        Returns:
            Dict: æŸ¥è¯¢ç»“æžœ
        """
        start_time = time.time()
        
        # åˆ›å»º Probe è¯·æ±‚
        probe_request = ProbeRequest(
            natural_query=natural_query,
            stage=QueryStage(stage),
            precision=PrecisionLevel(precision),
            context=context
        )
        
        try:
            # 1. æ£€æŸ¥è¯­ä¹‰ç¼“å­˜
            if self.memory_store:
                cached = await self._check_semantic_cache(probe_request)
                if cached:
                    self.cache_hits += 1
                    cached.was_cached = True
                    cached.execution_time = time.time() - start_time
                    return cached.model_dump()
            
            # 2. è§£æžæŸ¥è¯¢æ„å›¾ï¼ˆå¦‚æžœæœ‰ LLMï¼‰
            if self.llm_provider and not probe_request.sql_query:
                probe_request = await self._parse_query_intent(probe_request)
            
            # 3. æ ¹æ®é˜¶æ®µä¼˜åŒ–æŸ¥è¯¢
            probe_request = self._optimize_for_stage(probe_request)
            
            # 4. æ‰§è¡ŒæŸ¥è¯¢
            response = await self._execute_query(probe_request)
            
            # 5. ç”Ÿæˆå»ºè®®
            response = self._generate_suggestions(response, probe_request)
            
            # 6. ç¼“å­˜ç»“æžœ
            if self.memory_store and response.success:
                await self._cache_result(probe_request, response)
            
            self.query_count += 1
            response.execution_time = time.time() - start_time
            
            return response.model_dump()
            
        except Exception as e:
            # é”™è¯¯å¤„ç†
            execution_time = time.time() - start_time
            return ProbeResponse(
                request_id=probe_request.request_id,
                success=False,
                error=str(e),
                error_type=type(e).__name__,
                execution_time=execution_time,
                suggestions=self._generate_error_suggestions(e)
            ).model_dump()
    
    def execute(self, **kwargs) -> Dict[str, Any]:
        """
        åŒæ­¥æ‰§è¡Œ Probe æŸ¥è¯¢ï¼ˆAgenticX BaseTool è¦æ±‚çš„æ–¹æ³•ï¼‰
        
        è°ƒç”¨å¼‚æ­¥ç‰ˆæœ¬ aexecute
        """
        import asyncio
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        return loop.run_until_complete(self.aexecute(**kwargs))
    
    async def _check_semantic_cache(self, request: ProbeRequest) -> Optional[ProbeResponse]:
        """æ£€æŸ¥è¯­ä¹‰ç¼“å­˜ï¼ˆåˆ©ç”¨ 80-90% çš„æŸ¥è¯¢å†—ä½™ï¼‰"""
        if not self.memory_store:
            return None
        
        # ä½¿ç”¨ AgenticMemoryStore çš„è¯­ä¹‰æœç´¢
        similar_queries = await self.memory_store.find_similar_probes(
            request.natural_query,
            threshold=0.8
        )
        
        if similar_queries:
            # è¿”å›žæœ€ç›¸ä¼¼çš„ç¼“å­˜ç»“æžœ
            return similar_queries[0]
        
        return None
    
    async def _parse_query_intent(self, request: ProbeRequest) -> ProbeRequest:
        """ä½¿ç”¨ LLM è§£æžæŸ¥è¯¢æ„å›¾"""
        if not self.llm_provider:
            return request
        
        prompt = f"""
        åˆ†æžä»¥ä¸‹è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œç”Ÿæˆå¯¹åº”çš„ SQL è¯­å¥ï¼š
        
        æŸ¥è¯¢: {request.natural_query}
        ä¸Šä¸‹æ–‡: {request.context}
        ç²¾åº¦è¦æ±‚: {request.precision.value}
        
        åªè¿”å›ž SQL è¯­å¥ï¼Œä¸è¦æœ‰å…¶ä»–è¯´æ˜Žã€‚
        """
        
        try:
            response = await self.llm_provider.ainvoke(prompt)
            request.sql_query = self._extract_sql(response.content)
        except Exception as e:
            # LLM å¤±è´¥æ—¶ä½¿ç”¨ç®€å•çš„è§„åˆ™
            request.sql_query = self._generate_simple_sql(request.natural_query)
        
        return request
    
    def _extract_sql(self, llm_response: str) -> str:
        """ä»Ž LLM å“åº”ä¸­æå– SQL"""
        import re
        
        # æå–ä»£ç å—ä¸­çš„ SQL
        sql_match = re.search(r'```sql\n(.*?)\n```', llm_response, re.DOTALL)
        if sql_match:
            return sql_match.group(1).strip()
        
        # æå–æ™®é€šä»£ç å—
        code_match = re.search(r'```\n(.*?)\n```', llm_response, re.DOTALL)
        if code_match:
            return code_match.group(1).strip()
        
        return llm_response.strip()
    
    def _generate_simple_sql(self, natural_query: str) -> str:
        """ç”Ÿæˆç®€å•çš„ SQLï¼ˆfallbackï¼‰"""
        # ç®€åŒ–å®žçŽ°ï¼Œå®žé™…åº”è¯¥æ›´å¤æ‚
        return f"SELECT * FROM table WHERE condition LIMIT 10 -- {natural_query}"
    
    def _optimize_for_stage(self, request: ProbeRequest) -> ProbeRequest:
        """æ ¹æ®æŸ¥è¯¢é˜¶æ®µä¼˜åŒ–è¯·æ±‚"""
        if request.stage == QueryStage.METADATA_EXPLORATION:
            # å…ƒæ•°æ®æŽ¢ç´¢ï¼šå¿«é€Ÿã€è¿‘ä¼¼
            request.terminate_early = True
            request.max_rows = request.max_rows or 10
            if request.precision == PrecisionLevel.EXACT:
                request.precision = PrecisionLevel.SAMPLE
        
        elif request.stage == QueryStage.SOLUTION_FORMULATION:
            # è§£å†³æ–¹æ¡ˆåˆ¶å®šï¼šå¹³è¡¡é€Ÿåº¦å’Œå‡†ç¡®æ€§
            request.max_rows = request.max_rows or 100
            if request.precision == PrecisionLevel.EXACT:
                request.precision = PrecisionLevel.APPROXIMATE
        
        # FULL_VALIDATION ä¿æŒåŽŸæ ·
        
        return request
    
    async def _execute_query(self, request: ProbeRequest) -> ProbeResponse:
        """æ‰§è¡ŒæŸ¥è¯¢"""
        if self.database:
            return await self._execute_with_database(request)
        else:
            # æ²¡æœ‰æ•°æ®åº“è¿žæŽ¥æ—¶ï¼Œè¿”å›žæ¨¡æ‹Ÿç»“æžœ
            return self._mock_execution(request)
    
    async def _execute_with_database(self, request: ProbeRequest) -> ProbeResponse:
        """ä½¿ç”¨æ•°æ®åº“è¿žæŽ¥æ‰§è¡ŒæŸ¥è¯¢"""
        try:
            result = await self.database.execute(request.sql_query)
            
            return ProbeResponse(
                request_id=request.request_id,
                success=True,
                data=result.get("data", []),
                executed_sql=request.sql_query,
                rows_returned=result.get("rows_returned", 0),
                rows_scanned=result.get("rows_scanned", 0),
                actual_precision=request.precision
            )
        except Exception as e:
            return ProbeResponse(
                request_id=request.request_id,
                success=False,
                error=str(e),
                error_type=type(e).__name__
            )
    
    def _mock_execution(self, request: ProbeRequest) -> ProbeResponse:
        """æ¨¡æ‹Ÿæ‰§è¡Œï¼ˆç”¨äºŽæ¼”ç¤ºï¼‰"""
        mock_data = [
            {"id": 1, "name": "Product A", "sales": 150},
            {"id": 2, "name": "Product B", "sales": 200},
            {"id": 3, "name": "Product C", "sales": 100},
        ]
        
        rows = 3 if request.precision == PrecisionLevel.SAMPLE else 10
        if request.max_rows:
            rows = min(rows, request.max_rows)
        
        return ProbeResponse(
            request_id=request.request_id,
            success=True,
            data=mock_data[:rows],
            executed_sql=request.sql_query or "SELECT * FROM mock_table",
            rows_returned=len(mock_data[:rows]),
            rows_scanned=100,
            actual_precision=request.precision,
            confidence=0.95 if request.precision != PrecisionLevel.EXACT else 1.0,
            is_approximate=request.precision != PrecisionLevel.EXACT
        )
    
    def _generate_suggestions(self, response: ProbeResponse, request: ProbeRequest) -> ProbeResponse:
        """ç”Ÿæˆå»ºè®®"""
        suggestions = []
        
        if request.stage == QueryStage.METADATA_EXPLORATION:
            suggestions.append("âœ… å…ƒæ•°æ®æŽ¢ç´¢å®Œæˆï¼Œå¯ä»¥å¼€å§‹åˆ¶å®šè§£å†³æ–¹æ¡ˆ")
        
        elif request.stage == QueryStage.SOLUTION_FORMULATION:
            suggestions.append("ðŸ’¡ å»ºè®®è¿›è¡Œå®Œæ•´éªŒè¯ä»¥èŽ·å–ç²¾ç¡®ç»“æžœ")
        
        if request.precision != PrecisionLevel.EXACT:
            suggestions.append(f"âš ï¸ å½“å‰ä½¿ç”¨{request.precision.value}ç²¾åº¦ï¼Œå¦‚éœ€ç²¾ç¡®ç»“æžœè¯·ä½¿ç”¨ exact ç²¾åº¦")
        
        response.suggestions = suggestions
        return response
    
    def _generate_error_suggestions(self, error: Exception) -> list:
        """ç”Ÿæˆé”™è¯¯å»ºè®®"""
        error_str = str(error).lower()
        
        if "timeout" in error_str:
            return [
                "æŸ¥è¯¢è¶…æ—¶ï¼Œå»ºè®®ï¼š",
                "1. å¢žåŠ è¶…æ—¶æ—¶é—´",
                "2. ä½¿ç”¨è¿‘ä¼¼æŸ¥è¯¢ï¼ˆapproximateï¼‰",
                "3. æ·»åŠ æ›´å¤šè¿‡æ»¤æ¡ä»¶"
            ]
        elif "syntax" in error_str:
            return [
                "SQL è¯­æ³•é”™è¯¯ï¼Œå»ºè®®ï¼š",
                "1. ä½¿ç”¨å…ƒæ•°æ®æŽ¢ç´¢äº†è§£æ•°æ®ç»“æž„",
                "2. ç®€åŒ–æŸ¥è¯¢è¯­å¥"
            ]
        else:
            return ["æŸ¥è¯¢æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥æŸ¥è¯¢è¯­å¥å’Œæ•°æ®åº“è¿žæŽ¥"]
    
    async def _cache_result(self, request: ProbeRequest, response: ProbeResponse):
        """ç¼“å­˜æŸ¥è¯¢ç»“æžœåˆ° AgenticMemoryStore"""
        if not self.memory_store:
            return
        
        await self.memory_store.cache_probe_result(
            probe_request=request.model_dump(),
            probe_response=response.model_dump()
        )
    
    def get_stats(self) -> Dict[str, Any]:
        """èŽ·å–å·¥å…·ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_queries": self.query_count,
            "cache_hits": self.cache_hits,
            "cache_hit_rate": self.cache_hits / self.query_count if self.query_count > 0 else 0,
            "redundancy_savings": f"{(self.cache_hits / self.query_count * 100):.1f}%" if self.query_count > 0 else "0%"
        }

